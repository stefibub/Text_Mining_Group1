{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27a8d35-a752-4cbb-a6dc-31ca85f372a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pc/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  voted_up\n",
      "0  \"yeah man, i'm making a game. it's gonna be a ...     False\n",
      "1  i like the part where you jump on enemies and ...      True\n",
      "2  to be perfectly honest, it ends up feeling lik...     False\n",
      "3  didn't know this was planned as a series, so h...      True\n",
      "4              how do you even open this walkthrough     False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_cleaned_dataset.csv')\n",
    "filtered_df = df[['review_text', 'voted_up']].copy()\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5db6951-253b-47f9-87cb-5ce3143cb6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review_text  voted_up  \\\n",
      "0       \"yeah man, i'm making a game. it's gonna be a ...     False   \n",
      "1       i like the part where you jump on enemies and ...      True   \n",
      "2       to be perfectly honest, it ends up feeling lik...     False   \n",
      "3       didn't know this was planned as a series, so h...      True   \n",
      "4                   how do you even open this walkthrough     False   \n",
      "...                                                   ...       ...   \n",
      "165847   you don't need a review to know what this is. :)      True   \n",
      "165848  the h-content in this dlc is very nice with 1 ...     False   \n",
      "165849  as usual with this stuff, i like the pin-ups, ...      True   \n",
      "165850  i know its just a demo....but damn the game is...     False   \n",
      "165851                    i like the module on this ship.      True   \n",
      "\n",
      "        compound_score  \n",
      "0            -0.177789  \n",
      "1            -0.680800  \n",
      "2             0.510333  \n",
      "3             0.520586  \n",
      "4             0.000000  \n",
      "...                ...  \n",
      "165847        0.229400  \n",
      "165848       -0.085533  \n",
      "165849        0.169840  \n",
      "165850       -0.148144  \n",
      "165851        0.361200  \n",
      "\n",
      "[165852 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_review_sentiment(review):\n",
    "    sentences = sent_tokenize(review)\n",
    "    compound_scores = []\n",
    "    for sentence in sentences:\n",
    "        sentiment_score = analyzer.polarity_scores(sentence)\n",
    "        compound_scores.append(sentiment_score['compound'])\n",
    "    if compound_scores:  # Check if list is not empty\n",
    "        average_compound = sum(compound_scores) / len(compound_scores)\n",
    "    else:\n",
    "        average_compound = 0  # Default to 0 if there are no sentences\n",
    "    return average_compound\n",
    "\n",
    "# Apply the function to each review in the DataFrame\n",
    "filtered_df['compound_score'] = filtered_df['review_text'].apply(analyze_review_sentiment)\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a400a836-9bc3-4ce7-8994-3cda031222d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text  voted_up  compound_score\n",
      "0  \"yeah man, i'm making a game. it's gonna be a ...     False       -0.177789\n",
      "1  i like the part where you jump on enemies and ...      True       -0.680800\n",
      "2  to be perfectly honest, it ends up feeling lik...     False        0.510333\n",
      "3  didn't know this was planned as a series, so h...      True        0.520586\n",
      "4              how do you even open this walkthrough     False        0.000000\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df.head())\n",
    "filtered_df = filtered_df[filtered_df['compound_score'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d87c25-6bf4-42e2-84a3-e06319799203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Recommended       0.47      0.80      0.59     37836\n",
      "    Recommended       0.92      0.72      0.80    118193\n",
      "\n",
      "       accuracy                           0.74    156029\n",
      "      macro avg       0.69      0.76      0.70    156029\n",
      "   weighted avg       0.81      0.74      0.75    156029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert compound scores to binary predictions (1 for recommended, 0 for not recommended)\n",
    "# Adjust the threshold if needed\n",
    "threshold = 0.2\n",
    "filtered_df['predicted_voted_up'] = (filtered_df['compound_score'] > threshold).astype(int)\n",
    "\n",
    "# Convert 'voted_up' from boolean to int (True to 1, False to 0)\n",
    "filtered_df['voted_up'] = filtered_df['voted_up'].astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(filtered_df['voted_up'], filtered_df['predicted_voted_up'], target_names=['Not Recommended', 'Recommended'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93b704a-8355-4234-bf2c-e9be7548c610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'filtered_df' is your DataFrame\n",
    "# Let's split the dataset into training and test sets first\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df['review_text'], filtered_df['voted_up'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for a baseline model approach\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True, max_features=10000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45aa4f5c-1a75-47e9-a389-7ab67e6e0f89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      7499\n",
      "           1       0.95      0.87      0.91     23707\n",
      "\n",
      "    accuracy                           0.87     31206\n",
      "   macro avg       0.82      0.87      0.84     31206\n",
      "weighted avg       0.89      0.87      0.87     31206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ca60e-0706-4b5e-89d3-5afbf62b66ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/pc/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        label = self.labels[idx]\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'][0],\n",
    "            'attention_mask': inputs['attention_mask'][0],\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Convert data to torch Dataset\n",
    "train_dataset = ReviewsDataset(X_train.tolist(), y_train.tolist(), tokenizer)\n",
    "test_dataset = ReviewsDataset(X_test.tolist(), y_test.tolist(), tokenizer)\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa1060-886b-4bb1-839b-e431e3303a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df2 = filtered_df[filtered_df['voted_up'] != filtered_df['predicted_voted_up']]\n",
    "\n",
    "# Select the first 100 reviews if there are at least 100, otherwise select all that match the criteria\n",
    "reviews_to_print = filtered_df2[['review_text', 'voted_up', 'predicted_voted_up', 'compound_score']][:100]\n",
    "\n",
    "# Print the text of the filtered reviews along with real and predicted values\n",
    "for index, row in reviews_to_print.iterrows():\n",
    "    print(f\"Review Text: {row['review_text']}\")\n",
    "    print(f\"Real Value: {row['voted_up']}\")\n",
    "    print(f\"Predicted Value: {row['predicted_voted_up']}\\n\")\n",
    "    print(f\"compound_score: {row['compound_score']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb74283-2aff-43ae-ab7a-a2df8fee2948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
