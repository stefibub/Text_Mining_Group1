{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - Assignment Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the LAB-2 assignment of the Text Mining course. It is about sentiment analysis.\n",
    "\n",
    "The aims of the assignment are:\n",
    "* Learn how to run a rule-based sentiment analysis module (VADER)\n",
    "* Learn how to run a machine learning sentiment analysis module (Scikit-Learn/ Naive Bayes)\n",
    "* Learn how to run scikit-learn metrics for the quantitative evaluation\n",
    "* Learn how to perform and interpret a quantitative evaluation of the outcomes of the tools (in terms of Precision, Recall, and F<sub>1</sub>)\n",
    "* Learn how to evaluate the results qualitatively (by examining the data) \n",
    "* Get insight into differences between the two applied methods\n",
    "* Get insight into the effects of using linguistic preprocessing\n",
    "* Be able to describe differences between the two methods in terms of their results\n",
    "* Get insight into issues when applying these methods across different  domains\n",
    "\n",
    "In this assignment, you are going to create your own gold standard set from 50 tweets. You will the VADER and scikit-learn classifiers to these tweets and evaluate the results by using evaluation metrics and inspecting the data.\n",
    "\n",
    "We recommend you go through the notebooks in the following order:\n",
    "* **Read the assignment (see below)**\n",
    "* **Lab3.2-Sentiment-analysis-with-VADER.ipynb**\n",
    "* **Lab3.3-Sentiment-analysis.with-scikit-learn.ipynb**\n",
    "* **Answer the questions of the assignment (see below) using the provided notebooks and submit**\n",
    "\n",
    "In this assignment you are asked to perform both quantitative evaluations and error analyses:\n",
    "* a quantitative evaluation concerns the scores (Precision, Recall, and F<sub>1</sub>) provided by scikit's classification_report. It includes the scores per category, as well as micro and macro averages. Discuss whether the scores are balanced or not between the different categories (positive, negative, neutral) and between precision and recall. Discuss the shortcomings (if any) of the classifier based on these scores\n",
    "* an error analysis regarding the misclassifications of the classifier. It involves going through the texts and trying to understand what has gone wrong. It servers to get insight in what could be done to improve the performance of the classifier. Do you observe patterns in misclassifications?  Discuss why these errors are made and propose ways to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io) and [Isa Maks](https://research.vu.nl/en/persons/e-maks). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: VADER assignments\n",
    "\n",
    "\n",
    "### Preparation (nothing to submit):\n",
    "To be able to answer the VADER questions you need to know how the tool works. \n",
    "* Read more about the VADER tool in [this blog](http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html).  \n",
    "* VADER provides 4 scores (positive, negative, neutral, compound). Be sure to understand what they mean and how they are calculated.\n",
    "* VADER uses rules to handle linguistic phenomena such as negation and intensification. Be sure to understand which rules are used, how they work, and why they are important.\n",
    "* VADER makes use of a sentiment lexicon. Have a look at the lexicon. Be sure to understand which information can be found there (lemma?, wordform?, part-of-speech?, polarity value?, word meaning?) What do all scores mean? https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) \n",
    "\n",
    "\n",
    "### [3.5 points] Question1:\n",
    "\n",
    "Regard the following sentences and their output as given by VADER. Regard sentences 1 to 7, and explain the outcome **for each sentence**. Take into account both the rules applied by VADER and the lexicon that is used. You will find that some of the results are reasonable, but others are not. Explain what is going wrong or not when correct and incorrect results are produced. \n",
    "\n",
    "```\n",
    "INPUT SENTENCE 1 I love apples\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}\n",
    "\n",
    "INPUT SENTENCE 2 I don't love apples\n",
    "VADER OUTPUT {'neg': 0.627, 'neu': 0.373, 'pos': 0.0, 'compound': -0.5216}\n",
    "\n",
    "INPUT SENTENCE 3 I love apples :-)\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.133, 'pos': 0.867, 'compound': 0.7579}\n",
    "\n",
    "INPUT SENTENCE 4 These houses are ruins\n",
    "VADER OUTPUT {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
    "\n",
    "INPUT SENTENCE 5 These houses are certainly not considered ruins\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.5867}\n",
    "\n",
    "INPUT SENTENCE 6 He lies in the chair in the garden\n",
    "VADER OUTPUT {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.4215}\n",
    "\n",
    "INPUT SENTENCE 7 This house is like any house\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER is a tool which classifies text into three sentiment categories : positive, negative and neutral.The last value listed \"compound\" provides a single, continuous measure of the text's overall sentiment (thus aggregating the individual positive, negative and neutrial without delving into specifics) for a quick assessment.All of these metrics can rande from -1 (very megative) to +1 (very positive). \n",
    "\n",
    "**Sentence 1** \n",
    "\"I love apples\"\n",
    "\n",
    "The word \"love\" has a strong positive sentiment. The high positive score and positive compound score seem reasonable in regards to the sentence analysed,this is validated by the abbsernce of negations.\n",
    "The analysis is correctly evaluated. \n",
    "\n",
    "**Sentence 2**\n",
    "\"I don't love apples\"\n",
    "\n",
    "Vader works with rules, in this case the output follows Vader's logic : the negation \"don't\" enhances the negative score for the word \"love\".  This negation erxplains the high negative score and negative compound score. \n",
    "The analysis is is correct (negation rule applied).\n",
    "\n",
    "**Sentence 3**\n",
    "\"I love apples :-)\"\n",
    "When comparing this sentence to the first one \"I love apple\" we can identify a higher positive score; this is due to how Vader evaluates emoticons as part of the lexicon. In this case a smiley emoticon boosts the positive sentiment score, therefore resulting in a higher positive and compound score than the first sentence. \n",
    "The analysis is correctly evaluated. \n",
    "\n",
    "**Sentence 4**\n",
    "\"These houses are ruins\"\n",
    "\n",
    "It is likely that the word \"ruins\" refers to a negative sentiment in Vader lexicon. Because this tool cannot grasp when the sentiment is context-dependent this outpput could be potentially ambiguous. The scores could be correct (could be neutral or negative depending on the interpretation) though it is not fully clear wehter the scores are accurate. A historical context for examples could mostly be neutral, while if it is a sad circumstance it negative score should be enhanced.\n",
    "\n",
    "**Sentence 5**\n",
    "\"These houses are certainly not considered ruins\"\n",
    "\n",
    "The word \"certainly\" describes a strong sentiment. As we saw with rule two a negation flips the sentiment from one extreme to the other. In this case we saw as the non negated sentence (number 4) had as output a tendency to be evaluated as negative or neutral. In this case, with the application of the negation rule, \"not\" intensifies \"certainly\" and the sentence is identified as positive (\"ruins\" has positive connotation).\n",
    "In our opinion the analysis is correct, but as sentence 4 could be ambiguous in the balance between quantites due to the complexity of the double negation. \n",
    "\n",
    "**Sentence 6**\n",
    "\"He lies in the chair in the garden\"\n",
    "\n",
    "Incorrect analysis . The veb lies is considered to have a negative connnotations (when referring to its meaning as cheating or misleading), while in this case the verb has only neutral connotation as it is describing a physical postion. This shows that this tool can misinterpret words with multiple meaning based on the context in which they are inserted.\n",
    "\n",
    "**Sentence 7**\n",
    "\"This house is like any house\"\n",
    "\n",
    "Incorrect or ambiguous analysis. The reasoning over this opinion is that Vader seems to assign some positivity (due to the lack of negation) or probably for the association of the word \"house\" with positive sentiments while the sentence is overall just neutral. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Points: 2.5] Exercise 2: Collecting 50 tweets for evaluation\n",
    "Collect 50 tweets. Try to find tweets that are interesting for sentiment analysis, e.g., very positive, neutral, and negative tweets. These could be your own tweets (typed in) or collected from the Twitter stream.\n",
    "\n",
    "We will store the tweets in the file **my_tweets.json** (use a text editor to edit).\n",
    "For each tweet, you should insert:\n",
    "* sentiment analysis label: negative | neutral | positive (this you determine yourself, this is not done by a computer)\n",
    "* the text of the tweet\n",
    "* the Tweet-URL\n",
    "\n",
    "from:\n",
    "```\n",
    "    \"1\": {\n",
    "        \"sentiment_label\": \"\",\n",
    "        \"text_of_tweet\": \"\",\n",
    "        \"tweet_url\": \"\",\n",
    "```\n",
    "to:\n",
    "```\n",
    "\"1\": {\n",
    "        \"sentiment_label\": \"positive\",\n",
    "        \"text_of_tweet\": \"All across America people chose to get involved, get engaged and stand up. Each of us can make a difference, and all of us ought to try. So go keep changing the world in 2018.\",\n",
    "        \"tweet_url\" : \"https://twitter.com/BarackObama/status/946775615893655552\",\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load your tweets with human annotation in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweets = json.load(open('my_tweets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'sentiment_label': 'positive', 'text_of_tweet': 'Just had the most amazing coffee at Cafe Bliss! ☕️ Starting my day off right!', 'tweet_url': 'https://twitter.com/example/status/0000000000001'}\n",
      "2 {'sentiment_label': 'positive', 'text_of_tweet': 'Finally finished my marathon, and I beat my personal best! Could not be happier! 🏃\\u200d♂️🎉', 'tweet_url': 'https://twitter.com/example/status/0000000000002'}\n",
      "3 {'sentiment_label': 'positive', 'text_of_tweet': 'Huge shoutout to the team for pulling off an incredible project under tight deadlines. #TeamworkMakesTheDreamWork', 'tweet_url': 'https://twitter.com/example/status/0000000000003'}\n",
      "4 {'sentiment_label': 'positive', 'text_of_tweet': 'The sunset today was breathtaking, nature is truly an incredible artist. 🌅', 'tweet_url': 'https://twitter.com/example/status/0000000000004'}\n",
      "5 {'sentiment_label': 'positive', 'text_of_tweet': \"Our garden's first tomatoes of the season! There's nothing like homegrown food. 🍅😊\", 'tweet_url': 'https://twitter.com/example/status/0000000000005'}\n",
      "6 {'sentiment_label': 'positive', 'text_of_tweet': 'Overwhelmed with gratitude for the surprise birthday party. Feeling loved and blessed. 🎉🎂', 'tweet_url': 'https://twitter.com/example/status/0000000000006'}\n",
      "7 {'sentiment_label': 'positive', 'text_of_tweet': 'Passed my certification exam on the first try! All the hard work paid off. 📚✅', 'tweet_url': 'https://twitter.com/example/status/0000000000007'}\n",
      "8 {'sentiment_label': 'positive', 'text_of_tweet': 'Saw a random act of kindness today that restored my faith in humanity. 💖', 'tweet_url': 'https://twitter.com/example/status/0000000000008'}\n",
      "9 {'sentiment_label': 'positive', 'text_of_tweet': 'Nothing beats a cozy evening with family, good food, and laughter. #Blessed', 'tweet_url': 'https://twitter.com/example/status/0000000000009'}\n",
      "10 {'sentiment_label': 'positive', 'text_of_tweet': \"Thrilled to announce I've been accepted into my dream program. Here's to new beginnings! 🍾🎓\", 'tweet_url': 'https://twitter.com/example/status/0000000000010'}\n",
      "11 {'sentiment_label': 'positive', 'text_of_tweet': 'To everyone who supported my small business in its first year, thank you from the bottom of my heart. 🙏🛍️', 'tweet_url': 'https://twitter.com/example/status/0000000000011'}\n",
      "12 {'sentiment_label': 'positive', 'text_of_tweet': 'Woke up to the news that my article has been published. Feeling incredibly proud and excited! 📰🎉', 'tweet_url': 'https://twitter.com/example/status/0000000000012'}\n",
      "13 {'sentiment_label': 'positive', 'text_of_tweet': \"After years of saving, we finally booked our dream vacation. Can't wait for the adventures that await! ✈️🌍\", 'tweet_url': 'https://twitter.com/example/status/0000000000013'}\n",
      "14 {'sentiment_label': 'positive', 'text_of_tweet': 'Adopted the cutest puppy today. Our family just got a little bigger and a lot happier! 🐶❤️', 'tweet_url': 'https://twitter.com/example/status/0000000000014'}\n",
      "15 {'sentiment_label': 'positive', 'text_of_tweet': \"Successfully ran my first workshop today. The feedback was incredibly positive, and I'm so motivated to do more! 🎤👏\", 'tweet_url': 'https://twitter.com/example/status/0000000000015'}\n",
      "16 {'sentiment_label': 'negative', 'text_of_tweet': 'Waited over an hour for food that arrived cold. Absolutely unacceptable service at this restaurant.', 'tweet_url': 'https://twitter.com/example/status/0000000000016'}\n",
      "17 {'sentiment_label': 'negative', 'text_of_tweet': \"Can't believe my flight got canceled at the last minute. Ruined my entire vacation plans. #worstday\", 'tweet_url': 'https://twitter.com/example/status/0000000000017'}\n",
      "18 {'sentiment_label': 'negative', 'text_of_tweet': 'The customer support was utterly useless. They kept transferring my call without solving my issue. #frustrated', 'tweet_url': 'https://twitter.com/example/status/0000000000018'}\n",
      "19 {'sentiment_label': 'negative', 'text_of_tweet': 'This new update has made the app practically unusable. It keeps crashing every few minutes.', 'tweet_url': 'https://twitter.com/example/status/0000000000019'}\n",
      "20 {'sentiment_label': 'negative', 'text_of_tweet': \"Feeling heartbroken over the news today. It's hard to find any hope in such tragedy.\", 'tweet_url': 'https://twitter.com/example/status/0000000000020'}\n",
      "21 {'sentiment_label': 'negative', 'text_of_tweet': \"The sequel to my favorite movie was a massive disappointment. It lacked the original's charm and depth.\", 'tweet_url': 'https://twitter.com/example/status/0000000000021'}\n",
      "22 {'sentiment_label': 'negative', 'text_of_tweet': 'Another sleepless night thanks to the construction noise outside. This is becoming unbearable. #tired', 'tweet_url': 'https://twitter.com/example/status/0000000000022'}\n",
      "23 {'sentiment_label': 'negative', 'text_of_tweet': 'Lost my wallet today with all my cards and ID. Feeling so stressed and helpless right now.', 'tweet_url': 'https://twitter.com/example/status/0000000000023'}\n",
      "24 {'sentiment_label': 'negative', 'text_of_tweet': 'The repair costs for my car are through the roof. Worst timing ever.', 'tweet_url': 'https://twitter.com/example/status/0000000000024'}\n",
      "25 {'sentiment_label': 'negative', 'text_of_tweet': 'Just found out my favorite band canceled their tour. Months of anticipation gone to waste.', 'tweet_url': 'https://twitter.com/example/status/0000000000025'}\n",
      "26 {'sentiment_label': 'negative', 'text_of_tweet': 'Dealing with insurance has been a nightmare. They find every excuse not to cover my claims.', 'tweet_url': 'https://twitter.com/example/status/0000000000026'}\n",
      "27 {'sentiment_label': 'negative', 'text_of_tweet': 'My package was lost in transit, and now I have to go through a lengthy process to get a refund. #frustration', 'tweet_url': 'https://twitter.com/example/status/0000000000027'}\n",
      "28 {'sentiment_label': 'negative', 'text_of_tweet': 'The hotel room looks nothing like the photos online. Completely misleading and overpriced.', 'tweet_url': 'https://twitter.com/example/status/0000000000028'}\n",
      "29 {'sentiment_label': 'negative', 'text_of_tweet': \"Feeling let down by people I thought I could trust. It's hard to know who your real friends are.\", 'tweet_url': 'https://twitter.com/example/status/0000000000029'}\n",
      "30 {'sentiment_label': 'negative', 'text_of_tweet': \"The new policy changes at work are making everyone's job more difficult. Morale is at an all-time low.\", 'tweet_url': 'https://twitter.com/example/status/0000000000030'}\n",
      "31 {'sentiment_label': 'neutral', 'text_of_tweet': 'The city council announced a new recycling program starting next month.', 'tweet_url': 'https://twitter.com/example/status/0000000000031'}\n",
      "32 {'sentiment_label': 'neutral', 'text_of_tweet': \"Reminder: Daylight Saving Time begins this weekend. Don't forget to set your clocks forward.\", 'tweet_url': 'https://twitter.com/example/status/0000000000032'}\n",
      "33 {'sentiment_label': 'neutral', 'text_of_tweet': \"Currently reading 'The History of Ancient Civilizations'. It's quite an informative book.\", 'tweet_url': 'https://twitter.com/example/status/0000000000033'}\n",
      "34 {'sentiment_label': 'neutral', 'text_of_tweet': 'The weather forecast predicts rain for the next three days.', 'tweet_url': 'https://twitter.com/example/status/0000000000034'}\n",
      "35 {'sentiment_label': 'neutral', 'text_of_tweet': 'The latest smartphone model features a longer battery life and improved camera resolution.', 'tweet_url': 'https://twitter.com/example/status/0000000000035'}\n",
      "36 {'sentiment_label': 'neutral', 'text_of_tweet': 'A new coffee shop opened on Main Street. They serve espresso, pastries, and sandwiches.', 'tweet_url': 'https://twitter.com/example/status/0000000000036'}\n",
      "37 {'sentiment_label': 'neutral', 'text_of_tweet': 'Traffic updates: The bridge on 5th avenue will be closed for maintenance next week.', 'tweet_url': 'https://twitter.com/example/status/0000000000037'}\n",
      "38 {'sentiment_label': 'neutral', 'text_of_tweet': 'Interesting fact: Honey never spoils. Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3000 years old.', 'tweet_url': 'https://twitter.com/example/status/0000000000038'}\n",
      "39 {'sentiment_label': 'neutral', 'text_of_tweet': 'Looking for book recommendations. Preferably non-fiction and historical genres.', 'tweet_url': 'https://twitter.com/example/status/0000000000039'}\n",
      "40 {'sentiment_label': 'neutral', 'text_of_tweet': 'The local library is hosting a free coding workshop next Saturday for beginners.', 'tweet_url': 'https://twitter.com/example/status/0000000000040'}\n",
      "41 {'sentiment_label': 'neutral', 'text_of_tweet': 'Scientists have discovered a new species of frog in the Amazon rainforest.', 'tweet_url': 'https://twitter.com/example/status/0000000000041'}\n",
      "42 {'sentiment_label': 'neutral', 'text_of_tweet': 'Today marks the 50th anniversary of the moon landing. A monumental moment in history.', 'tweet_url': 'https://twitter.com/example/status/0000000000042'}\n",
      "43 {'sentiment_label': 'neutral', 'text_of_tweet': 'A reminder that the office will be closed next Monday in observance of the holiday.', 'tweet_url': 'https://twitter.com/example/status/0000000000043'}\n",
      "44 {'sentiment_label': 'neutral', 'text_of_tweet': 'The annual community yard sale is scheduled for next weekend. Time to declutter!', 'tweet_url': 'https://twitter.com/example/status/0000000000044'}\n",
      "45 {'sentiment_label': 'neutral', 'text_of_tweet': \"NASA's latest Mars rover has successfully landed on the red planet. Awaiting first images.\", 'tweet_url': 'https://twitter.com/example/status/0000000000045'}\n",
      "46 {'sentiment_label': 'positive', 'text_of_tweet': 'Just got back from the most relaxing beach vacation ever. The sunsets were out of this world! 🌅', 'tweet_url': 'https://twitter.com/example/status/0000000000046'}\n",
      "47 {'sentiment_label': 'positive', 'text_of_tweet': \"Thrilled to announce I've been promoted to manager! Hard work really does pay off. 🎉\", 'tweet_url': 'https://twitter.com/example/status/0000000000047'}\n",
      "48 {'sentiment_label': 'neutral', 'text_of_tweet': \"The museum will be open late this Friday for a special exhibit viewing. Everyone's welcome!\", 'tweet_url': 'https://twitter.com/example/status/0000000000048'}\n",
      "49 {'sentiment_label': 'neutral', 'text_of_tweet': 'Interesting fact: The shortest war in history lasted only 38 minutes between Britain and Zanzibar on August 27, 1896.', 'tweet_url': 'https://twitter.com/example/status/0000000000049'}\n",
      "50 {'sentiment_label': 'negative', 'text_of_tweet': \"Extremely disappointed with my new laptop. It's slower than my old one and keeps freezing. 😞\", 'tweet_url': 'https://twitter.com/example/status/0000000000050'}\n"
     ]
    }
   ],
   "source": [
    "for id_, tweet_info in my_tweets.items():\n",
    "    print(id_, tweet_info)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 points] Question 3:\n",
    "\n",
    "Run VADER on your own tweets (see function **run_vader** from notebook **Lab2-Sentiment-analysis-using-VADER.ipynb**). You can use the code snippet below this explanation as a starting point. \n",
    "* [2.5 points] a. Perform a quantitative evaluation. Explain the different scores, and explain which scores are most relevant and why.\n",
    "* [2.5 points] b. Perform an error analysis: select 10 positive, 10 negative and 10 neutral tweets that are not correctly classified and try to understand why. Refer to the VADER-rules and the VADER-lexicon. Of course, if there are less than 10 errors for a category, you only have to check those. For example, if there are only 5 errors for positive tweets, you just describe those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_output_to_label(vader_output):\n",
    "    \"\"\"\n",
    "    map vader output e.g.,\n",
    "    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
    "    to one of the following values:\n",
    "    a) positive float -> 'positive'\n",
    "    b) 0.0 -> 'neutral'\n",
    "    c) negative float -> 'negative'\n",
    "    \n",
    "    :param dict vader_output: output dict from vader\n",
    "    \n",
    "    :rtype: str\n",
    "    :return: 'negative' | 'neutral' | 'positive'\n",
    "    \"\"\"\n",
    "    compound = vader_output['compound']\n",
    "    \n",
    "    if compound < 0:\n",
    "        return 'negative'\n",
    "    elif compound == 0.0:\n",
    "        return 'neutral'\n",
    "    elif compound > 0.0:\n",
    "        return 'positive'\n",
    "    \n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.0}) == 'neutral'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.01}) == 'positive'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': -0.01}) == 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "# settings (to change for different experiments)\n",
    "to_lemmatize = True \n",
    "pos = set()\n",
    "\n",
    "for id_, tweet_info in my_tweets.items():\n",
    "    the_tweet = tweet_info['text_of_tweet']\n",
    "    vader_output = ''# run vader\n",
    "    vader_label = ''# convert vader output to category\n",
    "    \n",
    "    tweets.append(the_tweet)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(tweet_info['sentiment_label'])\n",
    "    \n",
    "# use scikit-learn's classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 points] Question 4:\n",
    "Run VADER on the set of airline tweets with the following settings:\n",
    "\n",
    "* Run VADER (as it is) on the set of airline tweets \n",
    "* Run VADER on the set of airline tweets after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only adjectives\n",
    "* Run VADER on the set of airline tweets with only adjectives and after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only nouns\n",
    "* Run VADER on the set of airline tweets with only nouns and after having lemmatized the text\n",
    "* Run VADER on the set of airline tweets with only verbs\n",
    "* Run VADER on the set of airline tweets with only verbs and after having lemmatized the text\n",
    "\n",
    "* [1 point] a. Generate for all separate experiments the classification report, i.e., Precision, Recall, and F<sub>1</sub> scores per category as well as micro and macro averages. **Use a different code cell (or multiple code cells) for each experiment.**\n",
    "* [3 points] b. Compare the scores and explain what they tell you.\n",
    "* - Does lemmatisation help? Explain why or why not.\n",
    "* - Are all parts of speech equally important for sentiment analysis? Explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /Users/pc/Documents/GitHub/Text_Mining_Group1/Lab3/airlinetweets\n",
      "this will print True if the folder exists: True\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "airline_tweets_folder = cwd.joinpath('airlinetweets')\n",
    "print('path:', airline_tweets_folder)\n",
    "print('this will print True if the folder exists:', \n",
    "      airline_tweets_folder.exists())\n",
    "\n",
    "airline_tweets_train = load_files(str(airline_tweets_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: scikit-learn assignments\n",
    "### [4 points] Question 5\n",
    "Train the scikit-learn classifier (Naive Bayes) using the airline tweets.\n",
    "\n",
    "+ Train the model on the airline tweets with 80% training and 20% test set and default settings (TF-IDF representation, min_df=2)\n",
    "+ Train with different settings:\n",
    "    + with respect to vectorizing: TF-IDF ('airline_tfidf') vs. Bag of words representation ('airline_count') \n",
    "    + with respect to the frequency threshold (min_df). Carry out experiments with increasing values for document frequency (min_df = 2; min_df = 5; min_df =10) \n",
    "* [1 point] a. Generate a classification_report for all experiments\n",
    "* [3 points] b. Look at the results of the experiments with the different settings and try to explain why they differ: \n",
    "    + which category performs best, is this the case for any setting?\n",
    "    + does the frequency threshold affect the scores? Why or why not according to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /Users/pc/Documents/GitHub/Text_Mining_Group1/Lab3/airlinetweets\n",
      "this will print True if the folder exists: True\n",
      "\n",
      "Experiment: airline_tfidf with min_df=2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       326\n",
      "           1       0.85      0.68      0.76       321\n",
      "           2       0.81      0.83      0.82       304\n",
      "\n",
      "    accuracy                           0.81       951\n",
      "   macro avg       0.81      0.81      0.81       951\n",
      "weighted avg       0.81      0.81      0.81       951\n",
      "\n",
      "\n",
      "Experiment: airline_tfidf with min_df=5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       333\n",
      "           1       0.83      0.71      0.77       321\n",
      "           2       0.84      0.83      0.83       297\n",
      "\n",
      "    accuracy                           0.82       951\n",
      "   macro avg       0.82      0.82      0.82       951\n",
      "weighted avg       0.82      0.82      0.81       951\n",
      "\n",
      "\n",
      "Experiment: airline_tfidf with min_df=10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.86       352\n",
      "           1       0.77      0.71      0.74       304\n",
      "           2       0.83      0.81      0.82       295\n",
      "\n",
      "    accuracy                           0.81       951\n",
      "   macro avg       0.81      0.80      0.80       951\n",
      "weighted avg       0.81      0.81      0.81       951\n",
      "\n",
      "\n",
      "Experiment: airline_count with min_df=2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       346\n",
      "           1       0.86      0.77      0.81       295\n",
      "           2       0.85      0.86      0.86       310\n",
      "\n",
      "    accuracy                           0.85       951\n",
      "   macro avg       0.85      0.85      0.85       951\n",
      "weighted avg       0.85      0.85      0.85       951\n",
      "\n",
      "\n",
      "Experiment: airline_count with min_df=5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       343\n",
      "           1       0.82      0.73      0.77       303\n",
      "           2       0.83      0.86      0.84       305\n",
      "\n",
      "    accuracy                           0.83       951\n",
      "   macro avg       0.83      0.83      0.83       951\n",
      "weighted avg       0.83      0.83      0.83       951\n",
      "\n",
      "\n",
      "Experiment: airline_count with min_df=10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       372\n",
      "           1       0.82      0.75      0.78       307\n",
      "           2       0.78      0.81      0.79       272\n",
      "\n",
      "    accuracy                           0.82       951\n",
      "   macro avg       0.82      0.81      0.81       951\n",
      "weighted avg       0.82      0.82      0.82       951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "import pathlib\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "cwd = pathlib.Path.cwd()\n",
    "airline_tweets_folder = cwd.joinpath('airlinetweets')\n",
    "print('path:', airline_tweets_folder)\n",
    "print('this will print True if the folder exists:', \n",
    "      airline_tweets_folder.exists())\n",
    "\n",
    "airline_tweets_train = load_files(str(airline_tweets_folder))\n",
    "\n",
    "vectorizers = {\n",
    "    'airline_tfidf': TfidfVectorizer,\n",
    "    'airline_count': CountVectorizer\n",
    "}\n",
    "\n",
    "min_df_values = [2, 5, 10]\n",
    "\n",
    "for vectorizer_name, Vectorizer in vectorizers.items():\n",
    "    for min_df in min_df_values:\n",
    "        print(f\"\\nExperiment: {vectorizer_name} with min_df={min_df}\")\n",
    "        vectorizer = Vectorizer(min_df=min_df)\n",
    "        \n",
    "        airline_counts = vectorizer.fit_transform(airline_tweets_train.data)\n",
    "        \n",
    "        docs_train, docs_test, y_train, y_test = train_test_split(airline_counts,\n",
    "        airline_tweets_train.target,\n",
    "        test_size = 0.20 \n",
    "        )\n",
    "        \n",
    "        clf = MultinomialNB().fit(docs_train, y_train)\n",
    "        y_pred = clf.predict(docs_test)\n",
    "\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        print(report)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5.b\n",
    "\n",
    "Based on the classification reports from the experiments conducted with different settings we can analyze the results. The performance of each category varies with the vectorizing technique and the document frequency threshold (min_df). The BoW representation, especially at lower min_df values, tends to achieve slightly higher scores in precision and recall. The reason for that is probably can capture more specific terms that might be crucial. The best-performing category is BoW with min_df = 2.\n",
    "\n",
    "Increasing the min_df value leads to a decreases in scores. It affects scores because it determines which words are included in the models vocabulary. Words that appear in very low numbrt of documents might be too specific, reducing the model's ability to generalize. On the other hand, words that are too common (when min_df is set too high) may lead to the exclusion of terms that could have been useful for classification. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4 points] Question 6: Inspecting the best scoring features \n",
    "\n",
    "+ Train the scikit-learn classifier (Naive Bayes) model with the following settings (airline tweets 80% training and 20% test;  Bag of words representation ('airline_count'), min_df=2)\n",
    "* [1 point] a. Generate the list of best scoring features per class (see function **important_features_per_class** below) [1 point]\n",
    "* [3 points] b. Look at the lists and consider the following issues: \n",
    "    + [1 point] Which features did you expect for each separate class and why?\n",
    "    + [1 point] Which features did you not expect and why ? \n",
    "    + [1 point] The list contains all kinds of words such as names of airlines, punctuation, numbers and content words (e.g., 'delay' and 'bad'). Which words would you remove or keep when trying to improve the model and why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       368\n",
      "           1       0.83      0.69      0.76       290\n",
      "           2       0.81      0.84      0.82       293\n",
      "\n",
      "    accuracy                           0.82       951\n",
      "   macro avg       0.82      0.82      0.82       951\n",
      "weighted avg       0.82      0.82      0.82       951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=2)\n",
    "airline_counts = vectorizer.fit_transform(airline_tweets_train.data)\n",
    "        \n",
    "docs_train, docs_test, y_train, y_test = train_test_split(airline_counts,\n",
    "    airline_tweets_train.target,\n",
    "    test_size = 0.20)\n",
    "        \n",
    "clf = MultinomialNB().fit(docs_train, y_train)\n",
    "y_pred = clf.predict(docs_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words in negative documents\n",
      "0 1365.0 united\n",
      "0 738.0 to\n",
      "0 525.0 the\n",
      "0 392.0 flight\n",
      "0 380.0 and\n",
      "0 379.0 you\n",
      "0 320.0 for\n",
      "0 316.0 my\n",
      "0 303.0 on\n",
      "0 275.0 is\n",
      "0 265.0 in\n",
      "0 216.0 your\n",
      "0 196.0 it\n",
      "0 194.0 of\n",
      "0 185.0 that\n",
      "0 171.0 me\n",
      "0 168.0 not\n",
      "0 159.0 no\n",
      "0 158.0 have\n",
      "0 152.0 at\n",
      "0 149.0 was\n",
      "0 148.0 with\n",
      "0 118.0 can\n",
      "0 113.0 this\n",
      "0 108.0 we\n",
      "0 107.0 from\n",
      "0 104.0 virginamerica\n",
      "0 104.0 service\n",
      "0 104.0 be\n",
      "0 97.0 now\n",
      "0 96.0 an\n",
      "0 92.0 cancelled\n",
      "0 89.0 get\n",
      "0 86.0 they\n",
      "0 84.0 bag\n",
      "0 84.0 are\n",
      "0 83.0 plane\n",
      "0 83.0 but\n",
      "0 81.0 customer\n",
      "0 79.0 just\n",
      "0 79.0 delayed\n",
      "0 77.0 why\n",
      "0 74.0 time\n",
      "0 72.0 been\n",
      "0 71.0 what\n",
      "0 70.0 co\n",
      "0 69.0 hours\n",
      "0 69.0 do\n",
      "0 68.0 still\n",
      "0 68.0 so\n",
      "0 68.0 gate\n",
      "0 67.0 will\n",
      "0 65.0 http\n",
      "0 63.0 hour\n",
      "0 62.0 out\n",
      "0 61.0 help\n",
      "0 60.0 when\n",
      "0 60.0 up\n",
      "0 60.0 airline\n",
      "0 59.0 again\n",
      "0 57.0 amp\n",
      "0 56.0 how\n",
      "0 55.0 or\n",
      "0 55.0 about\n",
      "0 54.0 our\n",
      "0 54.0 if\n",
      "0 53.0 late\n",
      "0 52.0 as\n",
      "0 51.0 would\n",
      "0 51.0 had\n",
      "0 50.0 flights\n",
      "0 49.0 there\n",
      "0 49.0 has\n",
      "0 48.0 all\n",
      "0 48.0 after\n",
      "0 47.0 waiting\n",
      "0 47.0 don\n",
      "0 46.0 worst\n",
      "0 46.0 one\n",
      "0 46.0 by\n",
      "-----------------------------------------\n",
      "Important words in neutral documents\n",
      "1 611.0 to\n",
      "1 313.0 the\n",
      "1 312.0 jetblue\n",
      "1 267.0 united\n",
      "1 261.0 southwestair\n",
      "1 246.0 on\n",
      "1 246.0 flight\n",
      "1 243.0 you\n",
      "1 209.0 for\n",
      "1 206.0 my\n",
      "1 194.0 americanair\n",
      "1 192.0 co\n",
      "1 183.0 in\n",
      "1 177.0 http\n",
      "1 174.0 can\n",
      "1 165.0 is\n",
      "1 155.0 usairways\n",
      "1 147.0 and\n",
      "1 137.0 it\n",
      "1 135.0 from\n",
      "1 134.0 of\n",
      "1 110.0 have\n",
      "1 109.0 me\n",
      "1 94.0 do\n",
      "1 87.0 get\n",
      "1 83.0 with\n",
      "1 75.0 virginamerica\n",
      "1 75.0 that\n",
      "1 75.0 any\n",
      "1 73.0 this\n",
      "1 72.0 at\n",
      "1 71.0 flights\n",
      "1 70.0 what\n",
      "1 70.0 be\n",
      "1 67.0 will\n",
      "1 66.0 are\n",
      "1 65.0 if\n",
      "1 63.0 please\n",
      "1 62.0 help\n",
      "1 60.0 we\n",
      "1 59.0 our\n",
      "1 57.0 need\n",
      "1 55.0 your\n",
      "1 54.0 just\n",
      "1 53.0 there\n",
      "1 51.0 dm\n",
      "1 49.0 how\n",
      "1 48.0 when\n",
      "1 46.0 now\n",
      "1 44.0 out\n",
      "1 44.0 or\n",
      "1 42.0 so\n",
      "1 40.0 know\n",
      "1 39.0 tomorrow\n",
      "1 39.0 thanks\n",
      "1 39.0 an\n",
      "1 38.0 not\n",
      "1 38.0 flying\n",
      "1 37.0 was\n",
      "1 37.0 fleet\n",
      "1 37.0 fleek\n",
      "1 37.0 change\n",
      "1 36.0 would\n",
      "1 36.0 way\n",
      "1 36.0 us\n",
      "1 36.0 am\n",
      "1 35.0 hi\n",
      "1 34.0 about\n",
      "1 33.0 but\n",
      "1 31.0 like\n",
      "1 31.0 cancelled\n",
      "1 31.0 as\n",
      "1 30.0 amp\n",
      "1 29.0 one\n",
      "1 29.0 fly\n",
      "1 26.0 number\n",
      "1 26.0 no\n",
      "1 26.0 check\n",
      "1 26.0 all\n",
      "1 25.0 see\n",
      "-----------------------------------------\n",
      "Important words in positive documents\n",
      "2 456.0 you\n",
      "2 437.0 to\n",
      "2 415.0 the\n",
      "2 331.0 for\n",
      "2 315.0 southwestair\n",
      "2 296.0 thanks\n",
      "2 290.0 jetblue\n",
      "2 246.0 united\n",
      "2 241.0 thank\n",
      "2 189.0 and\n",
      "2 184.0 flight\n",
      "2 170.0 americanair\n",
      "2 160.0 my\n",
      "2 153.0 on\n",
      "2 137.0 usairways\n",
      "2 133.0 great\n",
      "2 128.0 your\n",
      "2 126.0 in\n",
      "2 113.0 it\n",
      "2 110.0 me\n",
      "2 109.0 with\n",
      "2 105.0 is\n",
      "2 103.0 so\n",
      "2 101.0 of\n",
      "2 91.0 at\n",
      "2 89.0 service\n",
      "2 88.0 was\n",
      "2 86.0 virginamerica\n",
      "2 83.0 co\n",
      "2 74.0 love\n",
      "2 74.0 http\n",
      "2 72.0 are\n",
      "2 70.0 much\n",
      "2 67.0 this\n",
      "2 67.0 guys\n",
      "2 65.0 from\n",
      "2 65.0 best\n",
      "2 64.0 that\n",
      "2 62.0 just\n",
      "2 62.0 customer\n",
      "2 60.0 all\n",
      "2 53.0 awesome\n",
      "2 52.0 we\n",
      "2 49.0 have\n",
      "2 49.0 amazing\n",
      "2 48.0 got\n",
      "2 48.0 be\n",
      "2 48.0 airline\n",
      "2 45.0 out\n",
      "2 44.0 good\n",
      "2 43.0 up\n",
      "2 42.0 very\n",
      "2 42.0 today\n",
      "2 41.0 will\n",
      "2 41.0 us\n",
      "2 40.0 time\n",
      "2 39.0 our\n",
      "2 39.0 get\n",
      "2 37.0 now\n",
      "2 37.0 crew\n",
      "2 35.0 not\n",
      "2 35.0 made\n",
      "2 35.0 amp\n",
      "2 34.0 help\n",
      "2 34.0 gate\n",
      "2 34.0 fly\n",
      "2 33.0 flying\n",
      "2 33.0 can\n",
      "2 32.0 they\n",
      "2 32.0 appreciate\n",
      "2 31.0 re\n",
      "2 31.0 an\n",
      "2 30.0 response\n",
      "2 29.0 do\n",
      "2 29.0 but\n",
      "2 28.0 well\n",
      "2 28.0 home\n",
      "2 28.0 back\n",
      "2 27.0 she\n",
      "2 27.0 see\n"
     ]
    }
   ],
   "source": [
    "def important_features_per_class(vectorizer,classifier,n=80):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names_out()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    topn_class3 = sorted(zip(classifier.feature_count_[2], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words in negative documents\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in neutral documents\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in positive documents\")\n",
    "    for coef, feat in topn_class3:\n",
    "        print(class_labels[2], coef, feat) \n",
    "\n",
    "important_features_per_class(vectorizer, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer B\n",
    "\n",
    "Expected features:\n",
    "1. For Negative we see words that are associated with the negative experience. Words like \"delay\", \"cancelled\", \"waiting\", \"late\" as well as general negative words like \"worst\".\n",
    "\n",
    "2. Negative features: Mostly we can nottice the name of the airlines which could be the part of general tweets about companies.\n",
    "\n",
    "3. Positive features: Here we can see expected positive words like \"thanks\", \"great\", \"love\", \"best\" and etc. which are highlighting satisfactory with airlines.\n",
    "\n",
    "Unexpected Features:\n",
    "\n",
    "Unexpected features across the classes include common stopwords like \"to\", \"the\", \"and\", and pronouns \"you\", \"my\". While their high frequency is understandable in NLP, their relevance to sentiment analysis is minimal. Moreover, the presence of specific airline names in all categories might be unexpected since these could either be part of positive feedback or complaints, indicating their presence doesn’t necessarily dictate sentiment.\n",
    "\n",
    "The words that we would remove:\n",
    "1. Stop words and pronouns, \"to\", \"the\", \"and\", \"you\", etc. They offer little sentiment-specific insight and removing them could help model to focus on the more meaningful features.\n",
    "\n",
    "2. Names of the airlines. They could be relevant to see the subject of the sentiment but they don't carry an sentiment value by themselves and could skew the results since some airlines (usually low-cost ones) getting more negative reviews than others.\n",
    "\n",
    "Words that must be keeped:\n",
    "\n",
    " 1. Words with clear sentiment, like \"delayed\", \"cancelled\", \"worst\", \"great\" are directly indicative of sentiment and are valuable for the model.\n",
    " 2. Service-Related like \"customer\", \"service\", \"bag\", \"gate\" and \"flight\" are relevant as they can be qualified by positive or negative descriptors, offering context to sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional! (will not  be graded)] Question 7\n",
    "Train the model on airline tweets and test it on your own set of tweets\n",
    "+ Train the model with the following settings (airline tweets 80% training and 20% test;  Bag of words representation ('airline_count'), min_df=2)\n",
    "+ Apply the model on your own set of tweets and generate the classification report\n",
    "* [1 point] a. Carry out a quantitative analysis.\n",
    "* [1 point] b. Carry out an error analysis on 10 correctly and 10 incorrectly classified tweets and discuss them\n",
    "* [2 points] c. Compare the results (cf. classification report) with the results obtained by VADER on the same tweets and discuss the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional! (will not be graded)] Question 8: trying to improve the model\n",
    "* [2 points] a. Think of some ways to improve the scikit-learn Naive Bayes model by playing with the settings or applying linguistic preprocessing (e.g., by filtering on part-of-speech, or removing punctuation). Do not change the classifier but continue using the Naive Bayes classifier. Explain what the effects might be of these other settings \n",
    "+ [1 point] b. Apply the model with at least one new setting (train on the airline tweets using 80% training, 20% test) and generate the scores\n",
    "* [1 point] c. Discuss whether the model achieved what you expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
